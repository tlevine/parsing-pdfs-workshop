ABSTRACT

Much of the worldâ€™s data are stored in portable document format (PDF) files.
This is not my preferred storage or presentation format, so I often convert
such files into databases, graphs, or spreadsheets. When I'm reading PDF
files, I ask these questions.

* Do we need to read the file contents at all?
* Do we only need to extract the text and/or images?
* Do we care about the layout of the file?

I take different approaches to parsing depending on the answers to these
questions. I'll show a few different approaches to parsing and analyzing PDF
files, and I'll discuss which approaches make sense in which situations. 
And we'll try parsing some PDF files.

BEFORE THE WORKSHOP

We are going to write programs that read PDF files. If there is
a PDF file that you want to read, bring it.

Also, install as many of the following packages as you can.

poppler-utils

* On GNU/Linux, your package manager probably has it.
* On Windows, you try http://blog.alivate.com.au/poppler-windows/

pdftk

* On GNU/Linux, your package manager probably has it.
* On windows, try https://www.pdflabs.com/tools/pdftk-server/

Inkscape

* On GNU/Linux, your package manager probably has it.
* On Windows, try http://inkscape.org/en/download/windows/

Tesseract

* On GNU/Linux, your package manager probably has it.
* On Windows, try https://code.google.com/p/tesseract-ocr/wiki/ReadMe

AGENDA

Tom is going to parse a few PDF files in a few different ways each,
and you're going to ask him questions so that he doesn't get boring.

1. Looking through a large body of PDFs (wetlands permit application notices)
  * ls, &c.
  * pdftotext
  * pdfimages
2. Doing silly keyword searches
  * pdfimages and tesseract
  * grep with regular expressions
3. Inspecting the structure of a PDF (both wetlands and Scarsdale)
  * pdftohtml and open a web browser
  * Inkscape

The basic approach is pretty much always going to be to convert the PDF
to some sort of plain text and then to use typical text-parsing methods.

After Tom shows you all the different ways, you are going to try them!

PROGRAMS

From most lossy to least lossy

1. Basic file analysis tools (ls or another language's equivalent)
2. PDF metadata tools (pdfinfo or an equivalent)
3. pdftotext
4. pdftohtml -xml
5. Inkscape (maybe via pdf2svg)
6. Things like PDFMiner

Things for OCR

1. pdfimages
2. tesseract
3. There's probably some fancier thing just for PDFs, but I haven't used it.
4. convert (from ImageMagick) for converting image formats

Other things to look at

* Tabula
* Overview
* Itext

OTHER THINGS TO THINK ABOUT

I don't understand how PDF files work, so I convert them to an intermediary
format that I do understand. We tend to lose information when we convert files.
I choose the intermediary format that removes the most information possible
while still preserving the information that I care about; this creates a file
that has the information that I need but is easier to work with.

There are all sorts of ways of encoding data in PDF files, so it's not like
there's a straightforward PDF-to-spreadsheet conversion. (This is just like
any other file format.) Figure out what data you want to extract from the
files, and select your parsing strategy accordingly.

And if it seems like too much work to get exactly what you want, try to come
up with something else that is easier to extract and that will still tell you
something similar.

Finally, it's quite hard to convert data formats without losing information,
so don't worry about losing information. You can always write a new parser
for any other information that you want.

RELATED THINGS

We are going to run programs from shells in order to do the PDF conversion.
If you want to embed this in a larger program, you might take a look at this.
http://thomaslevine.com/!/running-shell-commands/

If you use `pdftohtml -xml` or `inkscape`, you'll probably want to parse the
resulting XML output. See this page for some directions on doing that in
different languages.
http://thomaslevine.com/!/xml-parsers/

REFERENCES

http://thomaslevine.com/!/parsing-pdfs
https://github.com/tlevine/scarsdale-data
